{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI9Jgpz2sNB1"
      },
      "source": [
        "# 1. Installing dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyBjz73HsRYV"
      },
      "source": [
        "Here I use these 3 dependencies,\n",
        "1. Weavite for vector storage and retrieval.\n",
        "2. Google's generative AI for query generation (could have used open source model like phi-3 as well).\n",
        "3. Sentence transformers to create vector embeddings for the query sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH9-sSqksDZR",
        "outputId": "b08d57d2-38bc-4f51-8271-13ae837a70ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting weaviate-client==3.26.2\n",
            "  Downloading weaviate_client-3.26.2-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.4/120.4 kB\u001b[0m \u001b[31m639.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client==3.26.2) (2.31.0)\n",
            "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client==3.26.2)\n",
            "  Downloading validators-0.28.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting authlib<2.0.0,>=1.2.1 (from weaviate-client==3.26.2)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client==3.26.2) (42.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client==3.26.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client==3.26.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client==3.26.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client==3.26.2) (2024.6.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client==3.26.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client==3.26.2) (2.22)\n",
            "Installing collected packages: validators, authlib, weaviate-client\n",
            "Successfully installed authlib-1.3.1 validators-0.28.3 weaviate-client-3.26.2\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.6.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install weaviate-client==3.26.2\n",
        "!pip install google-generativeai\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HrbI4o7b4Xbk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = \"API-KEY\"\n",
        "genai.configure(api_key = os.environ['GOOGLE_API_KEY'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzWNefz7tHm2"
      },
      "source": [
        "# 2. Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWe2Y_UmtP46"
      },
      "source": [
        "For the pre-processing:\n",
        "\n",
        "1. I import the necessary libraries: pandas for data manipulation and SentenceTransformer for generating sentence embeddings.\n",
        "\n",
        "2. In the DataProcessor class, I initialize it with paths to a CSV file (containing schema information) and a TXT file (containing question-query pairs). The datasets (schema and question-query pairs) are manually extracted along with a few API calls to a combination of 4 models GPT4, Gemini, LLAMA3 and Claude, where the large language models were asked to generate query-answer pair given the schema of the database. I also load a pre-trained sentence transformer model for vector encoding of questions.\n",
        "\n",
        "3. My read_data method reads the schema data from the CSV file into a DataFrame. It then reads the TXT file, processes each line into a list of items (question, query, and database ID), and creates another DataFrame.\n",
        "\n",
        "4. The clean_data method drops any completely empty rows, merges the question-query DataFrame with the schema DataFrame based on the database ID, and cleans the 'db_schema' and 'gemini_mql' columns by removing newlines and extra spaces.\n",
        "\n",
        "5. In the generate_embeddings method, I use the pre-trained model to generate sentence embeddings for each question and add them as a new column in the DataFrame.\n",
        "\n",
        "6. The process method ties everything together by calling read_data, clean_data, and generate_embeddings in sequence, then returns the processed DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lvkpe4ttEV4",
        "outputId": "a3adbf3a-923a-4129-cb1c-cfc7aae0233c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, csv_path, txt_path):\n",
        "        \"\"\"\n",
        "        Initialize the DataProcessor with paths to the CSV and TXT files.\n",
        "\n",
        "        :param csv_path: Path to the CSV file containing schema information.\n",
        "        :param txt_path: Path to the TXT file containing question-query pairs.\n",
        "        \"\"\"\n",
        "        self.csv_path = csv_path\n",
        "        self.txt_path = txt_path\n",
        "        self.schema_append_df = None  # DataFrame to store schema data\n",
        "        self.df_append = None  # DataFrame to store processed data\n",
        "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')  # Load pre-trained sentence transformer model\n",
        "\n",
        "    def read_data(self):\n",
        "        \"\"\"\n",
        "        Read data from CSV and TXT files, process the TXT data into a structured format.\n",
        "        \"\"\"\n",
        "        # Read schema data from CSV\n",
        "        self.schema_append_df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        # Read and process data from TXT\n",
        "        with open(self.txt_path, 'r') as file:\n",
        "            data = file.read().split('\\n')[3:-1]  # Split by newline, skip header and footer\n",
        "\n",
        "        # Process each line into a list of items\n",
        "        rows = [row.split('|') for row in data]\n",
        "\n",
        "        # Clean each item in the rows\n",
        "        rows = [[item.strip().replace('```', '').replace('`', '') for item in row if item != ''] for row in rows]\n",
        "\n",
        "        # Filter rows with more than 3 items (assuming a valid row has 3 items)\n",
        "        rows = [row for row in rows if len(row) <= 3]\n",
        "\n",
        "        # Print rows with more than 3 items for debugging\n",
        "        for row in rows:\n",
        "            if len(row) > 3:\n",
        "                print(row[0], '-------', row[1], '------', row[2], '-------', row[3])\n",
        "\n",
        "        # Create DataFrame from processed rows\n",
        "        self.df_append = pd.DataFrame(rows, columns=['question', 'gemini_mql', 'db_id'])\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"\n",
        "        Clean the data by removing empty rows, merging with schema data, and cleaning string values.\n",
        "        \"\"\"\n",
        "        # Drop rows where all columns are NaN\n",
        "        self.df_append = self.df_append.dropna(how='all')\n",
        "\n",
        "        # Merge with schema data based on 'db_id'\n",
        "        self.df_append = pd.merge(self.schema_append_df, self.df_append, on='db_id')\n",
        "\n",
        "        # Clean 'db_schema' and 'gemini_mql' columns by removing newlines and extra spaces\n",
        "        self.df_append['db_schema'] = self.df_append['db_schema'].apply(lambda x: x.replace(\"\\n\", \"\")).apply(lambda x: x.replace(\"  \", \"\"))\n",
        "        self.df_append['gemini_mql'] = self.df_append['gemini_mql'].apply(lambda x: x.replace(\"\\n\", \"\")).apply(lambda x: x.replace(\"  \", \"\"))\n",
        "        self.df_append['gemini_mql'] = self.df_append['gemini_mql'].apply(lambda x: x.replace(\"```\", \"\")).apply(lambda x: x.replace(\"  \", \"\"))\n",
        "\n",
        "    def generate_embeddings(self):\n",
        "        \"\"\"\n",
        "        Generate sentence embeddings for each question using the pre-trained model.\n",
        "        \"\"\"\n",
        "        self.df_append['vector'] = self.df_append['question'].apply(lambda x: self.model.encode(x))\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"\n",
        "        Process the data by reading, cleaning, and generating embeddings.\n",
        "\n",
        "        :return: Processed DataFrame\n",
        "        \"\"\"\n",
        "        self.read_data()\n",
        "        self.clean_data()\n",
        "        self.generate_embeddings()\n",
        "        return self.df_append"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "SMgPWqqSvJnW",
        "outputId": "031c8508-0a2e-439a-e1ec-c27ed9386f50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"processed_df\",\n  \"rows\": 690,\n  \"fields\": [\n    {\n      \"column\": \"db_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"trips\",\n          \"companies\",\n          \"theaters\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"db_schema\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"{\\\"collections\\\": [{\\\"name\\\": \\\"trips\\\",\\\"indexes\\\": [{\\\"key\\\": {\\\"_id\\\": 1}}],\\\"uniqueIndexes\\\": [],\\\"document\\\": {\\\"properties\\\": {\\\"_id\\\": {\\\"bsonType\\\": \\\"objectId\\\"},\\\"tripduration\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"start_station_id\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"start_station_name\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"end_station_id\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"end_station_name\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"bikeid\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"usertype\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"birth_year\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"gender\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"start_station_location\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"type\\\": {\\\"bsonType\\\": \\\"string\\\",\\\"enum\\\": [\\\"Point\\\"]},\\\"coordinates\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"double\\\"}}}},\\\"end_station_location\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"type\\\": {\\\"bsonType\\\": \\\"string\\\",\\\"enum\\\": [\\\"Point\\\"]},\\\"coordinates\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"double\\\"}}}},\\\"start_time\\\": {\\\"bsonType\\\": \\\"date\\\"},\\\"stop_time\\\": {\\\"bsonType\\\": \\\"date\\\"}}}}],\\\"version\\\": 1}\",\n          \"{\\\"collections\\\": [{\\\"name\\\": \\\"companies\\\",\\\"indexes\\\": [{ \\\"key\\\": { \\\"_id\\\": 1 } },{ \\\"key\\\": { \\\"name\\\": 1 } },{ \\\"key\\\": { \\\"permalink\\\": 1 } },{ \\\"key\\\": { \\\"crunchbase_url\\\": 1 } }],\\\"uniqueIndexes\\\": [],\\\"document\\\": {\\\"properties\\\": {\\\"_id\\\": { \\\"bsonType\\\": \\\"objectId\\\" },\\\"name\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"permalink\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"crunchbase_url\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"homepage_url\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"blog_url\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"blog_feed_url\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"twitter_username\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"category_code\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"number_of_employees\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"founded_year\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"founded_month\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"founded_day\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"deadpooled_year\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"deadpooled_month\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"deadpooled_day\\\": { \\\"bsonType\\\": \\\"int\\\" },\\\"deadpooled_url\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"tag_list\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"alias_list\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"email_address\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"phone_number\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"description\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"created_at\\\": { \\\"bsonType\\\": \\\"date\\\" },\\\"updated_at\\\": { \\\"bsonType\\\": \\\"date\\\" },\\\"overview\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"image\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"available_sizes\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": [{ \\\"bsonType\\\": \\\"int\\\" },{ \\\"bsonType\\\": \\\"int\\\" },{ \\\"bsonType\\\": \\\"string\\\" }]}},\\\"attribution\\\": { \\\"bsonType\\\": \\\"string\\\" }}},\\\"products\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"name\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"permalink\\\": { \\\"bsonType\\\": \\\"string\\\" }}}},\\\"relationships\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"is_past\\\": { \\\"bsonType\\\": \\\"bool\\\" },\\\"title\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"person\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"first_name\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"last_name\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"permalink\\\": { \\\"bsonType\\\": \\\"string\\\" }}}}}},\\\"competitions\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"competitor\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"name\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"permalink\\\": { \\\"bsonType\\\": \\\"string\\\" }}}}}},\\\"offices\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"description\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"address1\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"address2\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"zip_code\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"city\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"state_code\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"country_code\\\": { \\\"bsonType\\\": \\\"string\\\" },\\\"latitude\\\": { \\\"bsonType\\\": \\\"double\\\" },\\\"longitude\\\": { \\\"bsonType\\\": \\\"double\\\" }}}},\\\"total_money_raised\\\": { \\\"bsonType\\\": \\\"string\\\" }}}}],\\\"version\\\": 1}\",\n          \"{\\\"collections\\\": [{\\\"name\\\": \\\"theaters\\\",\\\"indexes\\\": [{\\\"key\\\": {\\\"_id\\\": 1}},{\\\"key\\\": {\\\"theaterId\\\": 1}},{\\\"key\\\": {\\\"location.geo\\\": \\\"2dsphere\\\"}}],\\\"uniqueIndexes\\\": [],\\\"document\\\": {\\\"properties\\\": {\\\"_id\\\": {\\\"bsonType\\\": \\\"objectId\\\"},\\\"theaterId\\\": {\\\"bsonType\\\": \\\"int\\\"},\\\"location\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"address\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"street1\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"city\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"state\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"zipcode\\\": {\\\"bsonType\\\": \\\"string\\\"}}},\\\"geo\\\": {\\\"bsonType\\\": \\\"object\\\",\\\"properties\\\": {\\\"type\\\": {\\\"bsonType\\\": \\\"string\\\"},\\\"coordinates\\\": {\\\"bsonType\\\": \\\"array\\\",\\\"items\\\": {\\\"bsonType\\\": \\\"double\\\"}}}}}}}}}],\\\"version\\\": 1}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 689,\n        \"samples\": [\n          \"What is the minimum transaction amount for each symbol for a particular account (e.g., account_id = 12345) during a specific date range (e.g., between 2023-01-01 and 2023-01-31)?\",\n          \"Find the students whose lucky number of their first friend is 7.\",\n          \"Group customers by active status\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gemini_mql\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 682,\n        \"samples\": [\n          \"db.transactions.aggregate([{$match: {account_id: 12345, bucket_start_date: {$gte: new Date('2023-01-01'), $lte: new Date('2023-01-31')}}}, {$unwind: '$transactions'}, {$group: {_id: '$transactions.symbol', min_price: {$min: {$toDouble: '$transactions.price'}}}}])\",\n          \"db.movies.find({\\\"tomatoes.critic.rating\\\": {$gt: 9}, \\\"imdb.rating\\\": {$gt: 8.5}}).sort({title: 1})\",\n          \"db.theaters.aggregate([{ $match: { \\\"location.geo.type\\\": \\\"MultiPoint\\\" } }, { $group: { _id: null, count: { $sum: 1 } } }])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "processed_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-92cb5883-0478-4e9b-bb27-37e8063a8c43\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>db_id</th>\n",
              "      <th>db_schema</th>\n",
              "      <th>question</th>\n",
              "      <th>gemini_mql</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trips</td>\n",
              "      <td>{\"collections\": [{\"name\": \"trips\",\"indexes\": [...</td>\n",
              "      <td>How many trips started from stations with coor...</td>\n",
              "      <td>db.trips.find({ \"start_station_location.coordi...</td>\n",
              "      <td>[0.05888682, -0.057749037, -0.026752103, 0.007...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trips</td>\n",
              "      <td>{\"collections\": [{\"name\": \"trips\",\"indexes\": [...</td>\n",
              "      <td>Can you find trips where the start and end sta...</td>\n",
              "      <td>db.trips.find({ \"start_station_location\": { $e...</td>\n",
              "      <td>[0.08742453, -0.03934286, 0.015882788, 0.04409...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trips</td>\n",
              "      <td>{\"collections\": [{\"name\": \"trips\",\"indexes\": [...</td>\n",
              "      <td>What are the average latitude and longitude of...</td>\n",
              "      <td>db.trips.aggregate([ { $unwind: \"$start_statio...</td>\n",
              "      <td>[0.061616994, -0.07761997, -0.004470903, 0.015...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trips</td>\n",
              "      <td>{\"collections\": [{\"name\": \"trips\",\"indexes\": [...</td>\n",
              "      <td>How many trips had start stations located with...</td>\n",
              "      <td>db.trips.find({ \"start_station_location.coordi...</td>\n",
              "      <td>[0.069803596, -0.04402151, -0.03896904, 0.0408...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trips</td>\n",
              "      <td>{\"collections\": [{\"name\": \"trips\",\"indexes\": [...</td>\n",
              "      <td>Can you find trips where the start station lat...</td>\n",
              "      <td>db.trips.find({ \"start_station_location.coordi...</td>\n",
              "      <td>[0.09405282, -0.030613618, -0.0054845614, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>children</td>\n",
              "      <td>{\"collections\": [{\"name\": \"children\",\"indexes\"...</td>\n",
              "      <td>Find the names of students who have at least t...</td>\n",
              "      <td>db.children.find({favCity: {$size: {$gte: 2}},...</td>\n",
              "      <td>[0.06695643, -0.0020597824, -0.015720407, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>children</td>\n",
              "      <td>{\"collections\": [{\"name\": \"children\",\"indexes\"...</td>\n",
              "      <td>Retrieve the students who have at least two fr...</td>\n",
              "      <td>db.children.find({friends: {$size: {$gte: 2}},...</td>\n",
              "      <td>[-0.05059331, 0.03790658, -0.005245966, -0.039...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>children</td>\n",
              "      <td>{\"collections\": [{\"name\": \"children\",\"indexes\"...</td>\n",
              "      <td>Find the names of students who have at least t...</td>\n",
              "      <td>db.children.find({favCity: {$size: {$gte: 3}},...</td>\n",
              "      <td>[0.09914845, 0.026046542, -0.02419481, -0.0088...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>children</td>\n",
              "      <td>{\"collections\": [{\"name\": \"children\",\"indexes\"...</td>\n",
              "      <td>Find the names of students who have at least t...</td>\n",
              "      <td>db.children.find({favCity: {$size: {$gte: 3}},...</td>\n",
              "      <td>[0.10291177, 0.020334102, -0.01746659, -0.0032...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>children</td>\n",
              "      <td>{\"collections\": [{\"name\": \"children\",\"indexes\"...</td>\n",
              "      <td>Retrieve the students who have at least two fr...</td>\n",
              "      <td>db.children.find({friends: {$size: {$gte: 2}},...</td>\n",
              "      <td>[-0.0019321325, 0.06899262, -0.00324683, -0.05...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>690 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92cb5883-0478-4e9b-bb27-37e8063a8c43')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92cb5883-0478-4e9b-bb27-37e8063a8c43 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92cb5883-0478-4e9b-bb27-37e8063a8c43');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0420334b-94d5-410d-ab45-f05d88f58e81\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0420334b-94d5-410d-ab45-f05d88f58e81')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0420334b-94d5-410d-ab45-f05d88f58e81 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bd8d4189-550e-40e9-ab8d-b2bfad0f7c7e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('processed_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bd8d4189-550e-40e9-ab8d-b2bfad0f7c7e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('processed_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        db_id                                          db_schema  \\\n",
              "0       trips  {\"collections\": [{\"name\": \"trips\",\"indexes\": [...   \n",
              "1       trips  {\"collections\": [{\"name\": \"trips\",\"indexes\": [...   \n",
              "2       trips  {\"collections\": [{\"name\": \"trips\",\"indexes\": [...   \n",
              "3       trips  {\"collections\": [{\"name\": \"trips\",\"indexes\": [...   \n",
              "4       trips  {\"collections\": [{\"name\": \"trips\",\"indexes\": [...   \n",
              "..        ...                                                ...   \n",
              "685  children  {\"collections\": [{\"name\": \"children\",\"indexes\"...   \n",
              "686  children  {\"collections\": [{\"name\": \"children\",\"indexes\"...   \n",
              "687  children  {\"collections\": [{\"name\": \"children\",\"indexes\"...   \n",
              "688  children  {\"collections\": [{\"name\": \"children\",\"indexes\"...   \n",
              "689  children  {\"collections\": [{\"name\": \"children\",\"indexes\"...   \n",
              "\n",
              "                                              question  \\\n",
              "0    How many trips started from stations with coor...   \n",
              "1    Can you find trips where the start and end sta...   \n",
              "2    What are the average latitude and longitude of...   \n",
              "3    How many trips had start stations located with...   \n",
              "4    Can you find trips where the start station lat...   \n",
              "..                                                 ...   \n",
              "685  Find the names of students who have at least t...   \n",
              "686  Retrieve the students who have at least two fr...   \n",
              "687  Find the names of students who have at least t...   \n",
              "688  Find the names of students who have at least t...   \n",
              "689  Retrieve the students who have at least two fr...   \n",
              "\n",
              "                                            gemini_mql  \\\n",
              "0    db.trips.find({ \"start_station_location.coordi...   \n",
              "1    db.trips.find({ \"start_station_location\": { $e...   \n",
              "2    db.trips.aggregate([ { $unwind: \"$start_statio...   \n",
              "3    db.trips.find({ \"start_station_location.coordi...   \n",
              "4    db.trips.find({ \"start_station_location.coordi...   \n",
              "..                                                 ...   \n",
              "685  db.children.find({favCity: {$size: {$gte: 2}},...   \n",
              "686  db.children.find({friends: {$size: {$gte: 2}},...   \n",
              "687  db.children.find({favCity: {$size: {$gte: 3}},...   \n",
              "688  db.children.find({favCity: {$size: {$gte: 3}},...   \n",
              "689  db.children.find({friends: {$size: {$gte: 2}},...   \n",
              "\n",
              "                                                vector  \n",
              "0    [0.05888682, -0.057749037, -0.026752103, 0.007...  \n",
              "1    [0.08742453, -0.03934286, 0.015882788, 0.04409...  \n",
              "2    [0.061616994, -0.07761997, -0.004470903, 0.015...  \n",
              "3    [0.069803596, -0.04402151, -0.03896904, 0.0408...  \n",
              "4    [0.09405282, -0.030613618, -0.0054845614, 0.03...  \n",
              "..                                                 ...  \n",
              "685  [0.06695643, -0.0020597824, -0.015720407, -0.0...  \n",
              "686  [-0.05059331, 0.03790658, -0.005245966, -0.039...  \n",
              "687  [0.09914845, 0.026046542, -0.02419481, -0.0088...  \n",
              "688  [0.10291177, 0.020334102, -0.01746659, -0.0032...  \n",
              "689  [-0.0019321325, 0.06899262, -0.00324683, -0.05...  \n",
              "\n",
              "[690 rows x 5 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_path = '/content/drive/MyDrive/weavite/mongodb_array_object.csv'\n",
        "txt_path = '/content/drive/MyDrive/weavite/mongodb_array_object.txt'\n",
        "\n",
        "# Create DataProcessor instance and process data\n",
        "processor = DataProcessor(csv_path, txt_path)\n",
        "processed_df = processor.process()\n",
        "\n",
        "# Print the processed DataFrame\n",
        "processed_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Y3kWRJwXD1"
      },
      "source": [
        "# 3. Creating Weavite vector store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1IX_aK5wuc-"
      },
      "source": [
        "For the purpose of utilizing weavite vector store:\n",
        "\n",
        "I've created a Python class called WeaviateClient that interacts with Weaviate, a vector database and semantic search engine. My implementation uses Weaviate's embedded mode, which means it runs in-memory without needing a separate server. This can be great for development, testing, or small-scale applications where simplicity and quick setup are priorities.\n",
        "\n",
        "The class defined below has several methods:\n",
        "\n",
        "1. create_class: I use this to define a schema in Weaviate. It creates a new class (similar to a table in SQL) with specified properties (like columns) if it doesn't already exist. This is crucial for organizing and structuring your data.\n",
        "\n",
        "2. add_data_object: This method takes a pandas DataFrame and adds each row as a data object in Weaviate. Importantly, it associates each object with a vector (from the 'vector' column). These vectors are key because they represent your data in a high-dimensional space, allowing for semantic similarity searches.\n",
        "\n",
        "3. get_nearby_objects: This is where the magic happens. Given a query vector, this method finds the most similar objects in the specified class. It returns not just the objects, but also a certainty score indicating how similar they are. This is powerful for tasks like recommendation systems, anomaly detection, or finding semantically similar documents.\n",
        "\n",
        "**Why use Weaviate?**\n",
        "\n",
        "It's all about semantic search and working with unstructured data. Traditional databases are great for exact matches, but they struggle with \"find me something like this.\" With vector databases like Weaviate, you can:\n",
        "\n",
        "* Implement semantic search in text data (find documents with similar meaning, not just keyword matches)\n",
        "* Work with embeddings from machine learning models (like word embeddings, image features, etc.)\n",
        "* Build recommendation systems based on content similarity\n",
        "* Detect anomalies or duplicates by finding \"outlier\" vectors\n",
        "* Cluster similar items for data exploration or organization\n",
        "\n",
        "In my code, I'm setting the foundation for these applications. By storing data with its semantic vectors and providing a way to find similar items, I'm enabling all sorts of smart, meaning-based data operations. It's a step towards making your data not just searchable, but understandable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6ijPGhSEv-TC"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "\n",
        "class WeaviateClient:\n",
        "    def __init__(self):\n",
        "        # Initialize a Weaviate client using the embedded options\n",
        "        # This means Weaviate will run in-memory without requiring a separate server\n",
        "        self.client = weaviate.Client(\n",
        "            embedded_options=weaviate.embedded.EmbeddedOptions(),\n",
        "        )\n",
        "\n",
        "    def create_class(self, class_name, properties):\n",
        "        # Check if the class already exists in the Weaviate schema\n",
        "        if self.client.schema.exists(class_name):\n",
        "            print(f\"Class {class_name} already exists.\")\n",
        "            return\n",
        "        else:\n",
        "            print(f\"Creating class {class_name}...\")\n",
        "\n",
        "            # Define the class object with the given name and properties\n",
        "            class_obj = {\n",
        "                \"class\": class_name,\n",
        "                \"properties\": properties\n",
        "            }\n",
        "\n",
        "            # Create the class in Weaviate schema\n",
        "            new_class = self.client.schema.create_class(class_obj)\n",
        "\n",
        "            # Note: The return value 'new_class' is not used (commented out)\n",
        "            # return new_class\n",
        "\n",
        "    def add_data_object(self, class_name, df):\n",
        "        # Extract column names and vectors from the DataFrame\n",
        "        columns = df.columns.tolist()\n",
        "        vectors = df['vector'].tolist()\n",
        "\n",
        "        # Iterate through each row in the DataFrame\n",
        "        for index, row in df.iterrows():\n",
        "            # Create a data object dictionary from the row, excluding the 'vector' column\n",
        "            data_object = {columns[i]: row[columns[i]] for i in range(len(columns)) if columns[i] != 'vector'}\n",
        "\n",
        "            # Add the data object to the batch, along with its vector\n",
        "            self.client.batch.add_data_object(data_object, class_name, vector=vectors[index])\n",
        "\n",
        "        # Create all objects in the batch\n",
        "        self.client.batch.create_objects()\n",
        "\n",
        "    def get_nearby_objects(self, class_name, vector, retrieval_columns, limit=10):\n",
        "        # Define the query vector\n",
        "        near_vec = {\"vector\": vector}\n",
        "\n",
        "        # Build and execute the query:\n",
        "        # 1. Get objects of the specified class\n",
        "        # 2. Retrieve specified columns and the certainty score\n",
        "        # 3. Find objects near the given vector\n",
        "        # 4. Limit the results\n",
        "        res = self.client \\\n",
        "            .query.get(class_name, retrieval_columns + [\"_additional {certainty}\"]) \\\n",
        "            .with_near_vector(near_vec) \\\n",
        "            .with_limit(limit) \\\n",
        "            .do()\n",
        "\n",
        "        # Return the query results\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZB2QJJOyC4v",
        "outputId": "8192b8d7-7842-4acf-8eee-1ebcb33e53b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedded weaviate is already listening on port 8079\n",
            "Creating class MongoDB...\n",
            "Embedded weaviate wasn't listening on port 8079, so starting embedded weaviate again\n",
            "Started /root/.cache/weaviate-embedded: process ID 7397\n"
          ]
        }
      ],
      "source": [
        "class_name = 'MongoDB'\n",
        "properties = [\n",
        "        {\n",
        "          \"name\": \"db_id\",\n",
        "          \"dataType\": [\"text\"]\n",
        "        },\n",
        "        {\n",
        "          \"name\": \"db_schema\",\n",
        "          \"dataType\": [\"text\"]\n",
        "        },\n",
        "        {\n",
        "          \"name\": \"question\",\n",
        "          \"dataType\": [\"text\"]\n",
        "        },\n",
        "        {\n",
        "          \"name\": \"gemini_mql\",\n",
        "          \"dataType\": [\"text\"]\n",
        "        }\n",
        "      ]\n",
        "\n",
        "# Initialize WeaviateClient for vector database operations\n",
        "db_client = WeaviateClient()\n",
        "\n",
        "# Get Weaviate class configuration from config\n",
        "class_name = class_name\n",
        "properties = properties\n",
        "\n",
        "# Create a class in Weaviate and add processed data\n",
        "db_client.create_class(class_name, properties)\n",
        "db_client.add_data_object(class_name, processed_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WggEDfaYy87l"
      },
      "source": [
        "# 4. Query Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbvB_iIGzFTL"
      },
      "source": [
        "For the final part:\n",
        "\n",
        "I've developed a QueryGeneration class to generate queries based on given inputs. The core of my implementation is a combination of Google's Gemini Pro model for text generation and sentence transformers for encoding and re-ranking. Open source model could have also been used here for query generation, but due to being GPU poor I chose to go with closed source.\n",
        "\n",
        "My class initializes with a sentence transformer model for encoding questions, a prompt template for query generation, and a cross-encoder model ('BAAI/bge-reranker-base') for re-ranking. I also configure a Gemini Pro model with safety settings to block high-threshold harassment and hate speech.\n",
        "\n",
        "The main method, **generate_query**, takes inputs like class name, schema, question, and a database. It has a boolean parameter **rag** to toggle Retrieval-Augmented Generation (RAG). When RAG is enabled, I encode the input question, retrieve similar questions from the database, and use the cross-encoder to re-rank these retrieved questions based on their similarity to the input question.\n",
        "\n",
        "I then take the top two most similar questions as examples and use their associated schemas and queries to fill in my prompt template. This way, the model sees similar examples before generating a query for the current question. When RAG is disabled, I simply fill in the prompt with the given schema and question.\n",
        "\n",
        "Finally, I use the Gemini model to generate content based on the constructed prompt.\n",
        "\n",
        "The primary reason for using these technologies is to enhance query generation by leveraging both large language models (Gemini Pro) and information retrieval techniques (RAG). By providing similar examples to the model, I can guide it to generate more accurate and contextually relevant queries.\n",
        "\n",
        "It's worth noting that the model with RAG generally performs better than without RAG. This is because when RAG is enabled, the model sees examples of similar questions and their corresponding queries. This additional context helps the model understand the expected query structure and the relevant parts of the schema, resulting in more accurate query generation. In contrast, without RAG, the model has to infer the query structure solely from the given schema and question, which can be more challenging, especially for complex or ambiguous questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k6NMMYFTympo"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "class QueryGeneration:\n",
        "    def __init__(self, model):\n",
        "        # Initialize the QueryGeneration class with a sentence transformer model and a prompt\n",
        "        self.model = self.get_gemini_model()  # Get the Gemini model\n",
        "        self.encoding_model = model  # Sentence transformer model for encoding questions\n",
        "        # self.prompt = prompt  # Prompt template for query generation\n",
        "        self.cross_encoder = CrossEncoder('BAAI/bge-reranker-base')  # Cross-encoder for re-ranking\n",
        "\n",
        "    def get_gemini_model(self):\n",
        "        # Configure and return a Gemini Pro model with safety settings\n",
        "        safety_settings = [\n",
        "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_ONLY_HIGH\"}\n",
        "        ]\n",
        "        model = genai.GenerativeModel('gemini-pro', safety_settings=safety_settings)\n",
        "        return model\n",
        "\n",
        "    def generate_query(self, class_name, schema, question, db, prompt, rag=True):\n",
        "        # Generate a query based on the given class, schema, question, and database\n",
        "        # rag: boolean to enable/disable Retrieval-Augmented Generation\n",
        "\n",
        "        if rag:\n",
        "            # Encode the question using the sentence transformer model\n",
        "            vector = self.encoding_model.encode(question)\n",
        "\n",
        "            # Retrieve nearby objects from the database using the question vector\n",
        "            res = db.get_nearby_objects(class_name, vector, ['db_schema', 'question', 'gemini_mql'], limit=10)\n",
        "            hits = res[\"data\"][\"Get\"][class_name]\n",
        "\n",
        "            # Prepare inputs for cross-encoder (question pairs)\n",
        "            cross_inp = [[question, hit['question']] for hit in hits]\n",
        "\n",
        "            # Get cross-encoder scores for re-ranking\n",
        "            cross_scores = self.cross_encoder.predict(cross_inp)\n",
        "\n",
        "            # Add cross-encoder scores to hits\n",
        "            for idx in range(len(cross_scores)):\n",
        "                hits[idx]['cross-score'] = cross_scores[idx]\n",
        "\n",
        "            # Sort hits by cross-encoder scores in descending order\n",
        "            hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "\n",
        "            # Get the top two hits as examples\n",
        "            example1 = hits[0]\n",
        "            example2 = hits[1]\n",
        "\n",
        "            # Extract schema, question, and query from the examples\n",
        "            EXAMPLE1_SCHEMA, EXAMPLE1_QUESTION, EXAMPLE1_QUERY = example1['db_schema'], example1['question'], example1['gemini_mql']\n",
        "            EXAMPLE2_SCHEMA, EXAMPLE2_QUESTION, EXAMPLE2_QUERY = example2['db_schema'], example2['question'], example2['gemini_mql']\n",
        "\n",
        "            # Replace placeholders in the prompt with actual values\n",
        "            prompt = prompt.replace(\"{{SCHEMA}}\", schema).replace(\"{{QUESTION}}\", question)\n",
        "            prompt = prompt.replace(\"{{EXAMPLE1_SCHEMA}}\", EXAMPLE1_SCHEMA).replace(\"{{EXAMPLE1_QUESTION}}\", EXAMPLE1_QUESTION).replace(\"{{EXAMPLE1_QUERY}}\", EXAMPLE1_QUERY)\n",
        "            prompt = prompt.replace(\"{{EXAMPLE2_SCHEMA}}\", EXAMPLE2_SCHEMA).replace(\"{{EXAMPLE2_QUESTION}}\", EXAMPLE2_QUESTION).replace(\"{{EXAMPLE2_QUERY}}\", EXAMPLE2_QUERY)\n",
        "\n",
        "        else:\n",
        "            # If RAG is disabled, just replace schema and question in the prompt\n",
        "            prompt = prompt.replace(\"{{SCHEMA}}\", schema).replace(\"{{QUESTION}}\", question)\n",
        "\n",
        "        # Generate content using the Gemini model with the constructed prompt\n",
        "        return self.model.generate_content(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkveIhMJ2yBz"
      },
      "source": [
        "#### Both of the below prompts were generated using the Anthropic prompt generator, and were then rigourously tested and improved to work well with the Gemini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMcidXMbykg4",
        "outputId": "3db738c9-bff6-499a-f27a-441afa0e520f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "prompt_rag = \"\"\"I will provide you with the schema for a MongoDB database, along with two examples of natural language questions and their corresponding MongoDB queries. Your task is to convert a new natural language question into a MongoDB query that will retrieve the requested information from the database.\n",
        "\n",
        "Here is the schema for the MongoDB database:\n",
        "\n",
        "<schema>\n",
        "{{SCHEMA}}\n",
        "</schema>\n",
        "\n",
        "Here are two examples to help guide you:\n",
        "\n",
        "<example1>\n",
        "Schema:\n",
        "{{EXAMPLE1_SCHEMA}}\n",
        "\n",
        "Question: {{EXAMPLE1_QUESTION}}\n",
        "\n",
        "Query:\n",
        "{{EXAMPLE1_QUERY}}\n",
        "</example1>\n",
        "\n",
        "<example2>\n",
        "Schema:\n",
        "{{EXAMPLE2_SCHEMA}}\n",
        "\n",
        "Question: {{EXAMPLE2_QUESTION}}\n",
        "\n",
        "Query:\n",
        "{{EXAMPLE2_QUERY}}\n",
        "</example2>\n",
        "\n",
        "Now, here is the new question to convert into a MongoDB query:\n",
        "\n",
        "<question>\n",
        "{{QUESTION}}\n",
        "</question>\n",
        "\n",
        "Think through how to construct the appropriate MongoDB query to answer this question based on the provided schema. Write out your thought process in a <scratchpad>.\n",
        "\n",
        "Then, provide the final MongoDB query inside <query> tags. The query should be syntactically correct and fully functional to retrieve the requested data from the database.\n",
        "\n",
        "Remember to only use the fields and structure defined in the provided schema. If the question cannot be answered by the information in the database, say so.\"\"\"\n",
        "\n",
        "prompt_nonrag = \"\"\"I will provide you with the schema for a MongoDB database. Your task is to convert a new natural language question into a MongoDB query that will retrieve the requested information from the database.\n",
        "\n",
        "Here is the schema for the MongoDB database:\n",
        "\n",
        "<schema>\n",
        "{{SCHEMA}}\n",
        "</schema>\n",
        "\n",
        "Now, here is the new question to convert into a MongoDB query:\n",
        "\n",
        "<question>\n",
        "{{QUESTION}}\n",
        "</question>\n",
        "\n",
        "Think through how to construct the appropriate MongoDB query to answer this question based on the provided schema. Write out your thought process in a <scratchpad>.\n",
        "\n",
        "Then, provide the final MongoDB query inside <query> tags. The query should be syntactically correct and fully functional to retrieve the requested data from the database.\n",
        "\n",
        "Remember to only use the fields and structure defined in the provided schema. If the question cannot be answered by the information in the database, say so.\"\"\"\n",
        "\n",
        "# Schema to perform query on.\n",
        "posts_schema = '''{\"collections\": [{\"name\": \"posts\",\"indexes\": [{\"key\": {\"_id\": 1}},{\"key\": {\"permalink\": 1}},{\"key\": {\"author\": 1}},{\"key\": {\"title\": 1}},{\"key\": {\"tags\": 1}},{\"key\": {\"comments.date\": 1}}],\"uniqueIndexes\": [],\"document\": {\"properties\": {\"_id\": {\"bsonType\": \"string\"},\"body\": {\"bsonType\": \"string\"},\"permalink\": {\"bsonType\": \"string\"},\"author\": {\"bsonType\": \"string\"},\"title\": {\"bsonType\": \"string\"},\"tags\": {\"bsonType\": \"array\",\"items\": {\"bsonType\": \"string\"}},\"comments\": {\"bsonType\": \"array\",\"items\": {\"bsonType\": \"object\",\"properties\": {\"body\": {\"bsonType\": \"string\"},\"email\": {\"bsonType\": \"string\"},\"author\": {\"bsonType\": \"string\"},\"date\": {\"bsonType\": \"date\"}}}}}}}],\"version\": 1}'''\n",
        "\n",
        "mongodb_querifier = QueryGeneration(processor.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jIMkkSeB3TGE",
        "outputId": "1ac7518c-e10e-449d-80f6-c0ca1adc5c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedded weaviate wasn't listening on port 8079, so starting embedded weaviate again\n",
            "Started /root/.cache/weaviate-embedded: process ID 13703\n"
          ]
        }
      ],
      "source": [
        "question = 'Find all the \"Sci-Fi\" related posts written by Chirayu with post length longer than 50 characters'\n",
        "output = mongodb_querifier.generate_query('MongoDB', posts_schema, question, db_client, prompt = prompt_rag, rag = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4vB0xc84LIv",
        "outputId": "e5f15339-bf89-4cef-9e26-e4710f2d3402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<scratchpad>\n",
            "1. First, we need to filter the posts based on the \"tags\" field. We want to find all the posts that have \"Sci-Fi\" in their tags array.\n",
            "2. Next, we need to filter the posts based on the \"author\" field. We want to find all the posts written by Chirayu.\n",
            "3. Finally, we need to filter the posts based on the length of the \"body\" field. We want to find all the posts where the body length is greater than 50 characters.\n",
            "\n",
            "So, the final query would be:\n",
            "```\n",
            "db.posts.find({\n",
            "  $and: [\n",
            "    { tags: \"Sci-Fi\" },\n",
            "    { author: \"Chirayu\" },\n",
            "    { $expr: { $gt: [{ $strLenCP: \"$body\" }, 50] } }\n",
            "  ]\n",
            "})\n",
            "```\n",
            "</scratchpad>\n",
            "\n",
            "<query>\n",
            "```\n",
            "db.posts.find({\n",
            "  $and: [\n",
            "    { tags: \"Sci-Fi\" },\n",
            "    { author: \"Chirayu\" },\n",
            "    { $expr: { $gt: [{ $strLenCP: \"$body\" }, 50] } }\n",
            "  ]\n",
            "})\n",
            "```\n",
            "</query>\n"
          ]
        }
      ],
      "source": [
        "# Model Generates { $expr: { $gt: [{ $strLenCP: \"$body\" }, 50] } } which returns the length of the string body using $strLenCP and then compares it to the integer 50.\n",
        "\n",
        "print(output.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Iczt4T64427L"
      },
      "outputs": [],
      "source": [
        "question = 'Find all the \"Sci-Fi\" related posts written by Chirayu with post length longer than 50 characters'\n",
        "output = mongodb_querifier.generate_query('MongoDB', posts_schema, question, db_client, prompt = prompt_nonrag, rag = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f83crbRA5FCA",
        "outputId": "2101b0cb-7322-485f-b703-a24fdb0c7101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<scratchpad>\n",
            "First, we need to identify posts related to \"Sci-Fi\" based on the 'tags' field. Since 'tags' is an array, we can use the $in operator to check if 'Sci-Fi' is included in the tags array.\n",
            "\n",
            "Next, we need to filter posts written by Chirayu based on the 'author' field.\n",
            "\n",
            "Finally, we need to filter posts with length longer than 50 characters. We can use the $gt operator to compare the length of the 'body' field with 50.\n",
            "</scratchpad>\n",
            "\n",
            "<query>\n",
            "{\n",
            "  $and: [\n",
            "    { tags: { $in: [\"Sci-Fi\"] } },\n",
            "    { author: \"Chirayu\" },\n",
            "    { body: { $gt: 50 } }\n",
            "  ]\n",
            "}\n",
            "</query>\n"
          ]
        }
      ],
      "source": [
        "# Model generates { body: { $gt: 50 } } where body is text and not an integer so this expression is not true.\n",
        "print(output.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLrnOR015KSy"
      },
      "source": [
        "It can be seen comparing the outputs of the 2 requests (with RAG and without RAG) that the LLM with relevant RAG is generating superior result compared to the one with no RAG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jKqZQq1592C"
      },
      "source": [
        "## Why do we need Re-ranking?\n",
        "\n",
        "Consider the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX-8zLah5GqL",
        "outputId": "6940b8d8-ba38-4e89-b355-2dbffe834ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7474851608276367 | books Find books with the author \"Jane Austen\" and a page count between 300 and 500 | db.books.find({\"authors\": \"Jane Austen\", \"pageCount\": {$gte: 300, $lte: 500}})\n",
            "---\n",
            "0.7126334309577942 | books Find books with the category \"History\" and published after 2010 | db.books.find({\"categories\": \"History\", \"publishedDate\": {$gt: new Date(\"2010-01-01\")}})\n",
            "---\n",
            "0.699367344379425 | customers Find customers with name 'John Doe' or 'Jane Smith' | db.customers.find({\"name\": {\"$in\": [\"John Doe\", \"Jane Smith\"]}})\n",
            "---\n",
            "0.6833274960517883 | trades Find trades with the ticker \"FB\" and a time range between March 1, 2023 and March 14, 2023. | db.trades.find({ticker: \"FB\", time: {$gte: ISODate(\"2023-03-01\"), $lt: ISODate(\"2023-03-15\")}})\n",
            "---\n",
            "0.6827490627765656 | children Get the students whose date of birth is between January 1, 2010, and December 31, 2012. | db.children.find({dob: {$gte: new Date(\"2010-01-01\"), $lte: new Date(\"2012-12-31\")}}, {first_name: 1, last_name: 1, dob: 1, _id: 0})\n",
            "---\n",
            "0.6818628311157227 | children Retrieve the students whose date of birth is in the month of June. | db.children.find({dob: {$gte: new Date(\"2000-06-01\"), $lte: new Date(\"2000-06-30\")}}, {first_name: 1, last_name: 1, dob: 1, _id: 0})\n",
            "---\n",
            "0.6804512739181519 | books List the titles of books published after January 1, 2010 | db.books.find({\"publishedDate\": {$gt: new Date(\"2010-01-01\")}}, {\"title\": 1, \"_id\": 0})\n",
            "---\n",
            "0.6798384785652161 | restaurants Find restaurants with grade date in February 2022. | db.restaurants.find({ 'grades.date': { $gte: ISODate('2022-02-01'), $lte: ISODate('2022-02-28') } })\n",
            "---\n",
            "0.6734524071216583 | restaurants Find restaurants with grade date in December 2021. | db.restaurants.find({ 'grades.date': { $gte: ISODate('2021-12-01'), $lte: ISODate('2021-12-31') } })\n",
            "---\n",
            "0.6729207634925842 | movies Find all movies with at least one writer in the \"writers\" array. | db.movies.find({writers: {$exists: true, $ne: []}})\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Both the first and second query are not good enough to guide the model towards right direction.\n",
        "\n",
        "near_vec = {\"vector\": processor.model.encode('''Find posts with comments from the author \"Jane Smith\" between January 1, 2022 and December 31, 2022''')}\n",
        "res = db_client.client \\\n",
        "    .query.get(\"MongoDB\", [\"db_id\", \"question\",\"gemini_mql\", \"_additional {certainty}\"]) \\\n",
        "    .with_near_vector(near_vec) \\\n",
        "    .with_limit(10) \\\n",
        "    .do()\n",
        "\n",
        "hits = res[\"data\"][\"Get\"][\"MongoDB\"]\n",
        "for post in res[\"data\"][\"Get\"][\"MongoDB\"]:\n",
        "        print(post[\"_additional\"][\"certainty\"], '|', post[\"db_id\"], post[\"question\"],'|', post[\"gemini_mql\"])\n",
        "        print('---')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNSj6yvW7TSp",
        "outputId": "41e831a6-affa-4229-e064-809e8026a360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07612825 | Find customers with name 'John Doe' or 'Jane Smith' | db.customers.find({\"name\": {\"$in\": [\"John Doe\", \"Jane Smith\"]}})\n",
            "0.020884207 | Get the students whose date of birth is between January 1, 2010, and December 31, 2012. | db.children.find({dob: {$gte: new Date(\"2010-01-01\"), $lte: new Date(\"2012-12-31\")}}, {first_name: 1, last_name: 1, dob: 1, _id: 0})\n",
            "0.003650334 | Find books with the author \"Jane Austen\" and a page count between 300 and 500 | db.books.find({\"authors\": \"Jane Austen\", \"pageCount\": {$gte: 300, $lte: 500}})\n",
            "0.0034265788 | Find books with the category \"History\" and published after 2010 | db.books.find({\"categories\": \"History\", \"publishedDate\": {$gt: new Date(\"2010-01-01\")}})\n",
            "0.0015753509 | Find all movies with at least one writer in the \"writers\" array. | db.movies.find({writers: {$exists: true, $ne: []}})\n",
            "0.0013581152 | Find restaurants with grade date in February 2022. | db.restaurants.find({ 'grades.date': { $gte: ISODate('2022-02-01'), $lte: ISODate('2022-02-28') } })\n",
            "0.0009143405 | Retrieve the students whose date of birth is in the month of June. | db.children.find({dob: {$gte: new Date(\"2000-06-01\"), $lte: new Date(\"2000-06-30\")}}, {first_name: 1, last_name: 1, dob: 1, _id: 0})\n",
            "0.0007381274 | Find restaurants with grade date in December 2021. | db.restaurants.find({ 'grades.date': { $gte: ISODate('2021-12-01'), $lte: ISODate('2021-12-31') } })\n",
            "0.00057209027 | List the titles of books published after January 1, 2010 | db.books.find({\"publishedDate\": {$gt: new Date(\"2010-01-01\")}}, {\"title\": 1, \"_id\": 0})\n",
            "0.0001740904 | Find trades with the ticker \"FB\" and a time range between March 1, 2023 and March 14, 2023. | db.trades.find({ticker: \"FB\", time: {$gte: ISODate(\"2023-03-01\"), $lt: ISODate(\"2023-03-15\")}})\n"
          ]
        }
      ],
      "source": [
        "# The second re-ranked query is exactly similar to what we want as an output from the model.\n",
        "\n",
        "query = '''Find posts with comments from the author \"Jane Smith\" between January 1, 2022 and December 31, 2022'''\n",
        "cross_inp = [[query, hit['question']] for hit in hits]\n",
        "cross_scores = mongodb_querifier.cross_encoder.predict(cross_inp)\n",
        "\n",
        "for idx in range(len(cross_scores)):\n",
        "    hits[idx]['cross-score'] = cross_scores[idx]\n",
        "\n",
        "hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "\n",
        "for hit in hits:\n",
        "    print(hit['cross-score'],'|', hit['question'], '|', hit['gemini_mql'])\n",
        "    print('---')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da22tZgE8c5g"
      },
      "source": [
        "As observed from the above example the re-ranked queries are more relevant to our input question and thus will guide the model towards the right path in generating the MongoDB query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzbFiz6d8t7o"
      },
      "source": [
        "## Why do we need RAG when we already have few-shot MongoDB query generation?\n",
        "\n",
        "The need for Retrieval-Augmented Generation (RAG) over few-shot examples for MongoDB query generation stems from the dynamic nature of RAG in providing more contextually relevant and specific examples compared to the static nature of few-shot learning. Here’s a breakdown of why RAG can be more beneficial:\n",
        "\n",
        "* Fixed Examples: The examples remain the same for every query, which might not always be relevant to the specific query context. This can lead to less accurate or less optimized query generation, as seen in the case of string length calculation above.\n",
        "\n",
        "* Contextual Relevance: By retrieving and using examples that are directly relevant to the current query, RAG can tailor the prompt to better fit the user's needs, improving the accuracy and quality of the generated MongoDB queries.\n",
        "\n",
        "* Complex Query Generation: For complex or less common queries, fixed examples may not provide sufficient guidance. RAG can retrieve specialized examples that better match the complexity of such queries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7rMOwi9-r9C"
      },
      "source": [
        "# 2.1 Build a front-end or presentation for your workflow\n",
        "\n",
        "I used streamlit for the purpose of front-end, because it is quick to implement.\n",
        "https://querifier.streamlit.app/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcSWirAO_QYK"
      },
      "source": [
        "# 2.2 Outline a potential growth pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IilfaGDaJX4d"
      },
      "source": [
        "For this approach:\n",
        "1. I started by importing pandas and reading a CSV file containing job postings data into a DataFrame called df.\n",
        "2. I checked for null values in the 'skills_desc' column and then selected the first 20,000 rows, for testing, storing them in df_test. I used only 20,000 rows because of compute limit, but it can be extended to include the complete dataframe.\n",
        "3. I preprocessed the 'title' and 'description' columns by converting them to lowercase and removing non-alphanumeric characters.\n",
        "4. I imported the BERTopic library for topic modeling and CountVectorizer from sklearn for text vectorization.\n",
        "5. To improve the model's performance, I used NLTK to download and include English stopwords in the CountVectorizer.\n",
        "6. I initialized a BERTopic model with the customized CountVectorizer, setting it to use English language and calculate probabilities.\n",
        "7. I fit and transformed the model on the combined 'title' and 'description' data, obtaining topics and their probabilities. The model performed better on combination of df_test['title'] and df_test['description'] compared to just the description.\n",
        "8. I defined a list of search terms related to data science and machine learning, and filtered the topics that contain these terms. Using this I obtained the clusters which contain AI/ML information.\n",
        "9. Finally, I tested the model with a sample job description for a machine learning role at Samsung Ads, which I found on linkedin, I transformed this example using the model and printed the predicted topic label and its description.\n",
        "\n",
        "This code demonstrates how I used BERTopic to automatically identify and categorize topics in job postings, with a focus on data science and machine learning roles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wao3yQ2NSEc4"
      },
      "source": [
        "**Reasons for using BERTopic against LDA**\n",
        "\n",
        "BERTopic is a state-of-the-art topic modeling technique that combines the power of BERT (Bidirectional Encoder Representations from Transformers) with traditional topic modeling methods like TF-IDF and c-TF-IDF (class-based TF-IDF). Here's why it's advantageous for our job posting analysis:\n",
        "\n",
        "1. Semantics Understanding: BERT is a pre-trained language model that understands the context and semantics of words. Unlike traditional methods like Latent Dirichlet Allocation (LDA) that treat words as independent tokens, BERT captures the nuanced meaning of words based on their context. This is crucial for job postings where terms like \"python\" could refer to a programming language or a snake, depending on the context.\n",
        "\n",
        "2. Handling Domain-Specific Language: Job postings often contain industry jargon, technical terms, and acronyms. BERT, being trained on a vast corpus of text, has a good grasp of such domain-specific language. This means it can better understand and group terms like \"ML\" (machine learning), \"AI\" (artificial intelligence) into relevant topics.\n",
        "\n",
        "3. Capturing Phrases: By using CountVectorizer with ngram_range=(1, 2), we allow BERTopic to consider both unigrams and bigrams. This is important because many job skills are expressed as phrases: \"machine learning\", \"data analysis\", \"project management\". Traditional methods might separate these, losing meaning, but BERTopic keeps them together.\n",
        "\n",
        "4. Improved Topic Coherence: BERTopic uses c-TF-IDF, which considers the frequency of words across topics, not just documents. This leads to more coherent topics. In our case, it helps distinguish between topics like \"data science\" and \"data entry\", even though both contain the word \"data\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npJrfovr625S",
        "outputId": "b340af4b-323d-4a26-9c8f-c406e4e7103c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.16.2-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.25.2)\n",
            "Collecting hdbscan>=0.8.29 (from bertopic)\n",
            "  Downloading hdbscan-0.8.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn>=0.5.0 (from bertopic)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.4)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (3.0.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Collecting cython<3,>=0.27 (from hdbscan>=0.8.29->bertopic)\n",
            "  Downloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.41.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.12.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Installing collected packages: cython, pynndescent, hdbscan, umap-learn, bertopic\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.10\n",
            "    Uninstalling Cython-3.0.10:\n",
            "      Successfully uninstalled Cython-3.0.10\n",
            "Successfully installed bertopic-0.16.2 cython-0.29.37 hdbscan-0.8.36 pynndescent-0.5.12 umap-learn-0.5.6\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5MSFkJt9tZYJ"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file containing job postings data\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/weavite/postings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "JtI9umJQvqce",
        "outputId": "618ddb3b-45a7-43a0-f206-d6481b9b83a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-71c069c5-43af-43bc-98f1-ba3128d524c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>company_name</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>pay_period</th>\n",
              "      <th>location</th>\n",
              "      <th>company_id</th>\n",
              "      <th>views</th>\n",
              "      <th>med_salary</th>\n",
              "      <th>...</th>\n",
              "      <th>expiry</th>\n",
              "      <th>closed_time</th>\n",
              "      <th>formatted_experience_level</th>\n",
              "      <th>skills_desc</th>\n",
              "      <th>listed_time</th>\n",
              "      <th>posting_domain</th>\n",
              "      <th>sponsored</th>\n",
              "      <th>work_type</th>\n",
              "      <th>currency</th>\n",
              "      <th>compensation_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>921716</td>\n",
              "      <td>Corcoran Sawyer Smith</td>\n",
              "      <td>Marketing Coordinator</td>\n",
              "      <td>Job descriptionA leading real estate firm in N...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>HOURLY</td>\n",
              "      <td>Princeton, NJ</td>\n",
              "      <td>2774458.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.715990e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
              "      <td>1.713398e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>FULL_TIME</td>\n",
              "      <td>USD</td>\n",
              "      <td>BASE_SALARY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1829192</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mental Health Therapist/Counselor</td>\n",
              "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>HOURLY</td>\n",
              "      <td>Fort Collins, CO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.715450e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.712858e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>FULL_TIME</td>\n",
              "      <td>USD</td>\n",
              "      <td>BASE_SALARY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10998357</td>\n",
              "      <td>The National Exemplar</td>\n",
              "      <td>Assitant Restaurant Manager</td>\n",
              "      <td>The National Exemplar is accepting application...</td>\n",
              "      <td>65000.0</td>\n",
              "      <td>YEARLY</td>\n",
              "      <td>Cincinnati, OH</td>\n",
              "      <td>64896719.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.715870e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We are currently accepting resumes for FOH - A...</td>\n",
              "      <td>1.713278e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>FULL_TIME</td>\n",
              "      <td>USD</td>\n",
              "      <td>BASE_SALARY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23221523</td>\n",
              "      <td>Abrams Fensterman, LLP</td>\n",
              "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
              "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
              "      <td>175000.0</td>\n",
              "      <td>YEARLY</td>\n",
              "      <td>New Hyde Park, NY</td>\n",
              "      <td>766262.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.715488e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This position requires a baseline understandin...</td>\n",
              "      <td>1.712896e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>FULL_TIME</td>\n",
              "      <td>USD</td>\n",
              "      <td>BASE_SALARY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35982263</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Service Technician</td>\n",
              "      <td>Looking for HVAC service tech with experience ...</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>YEARLY</td>\n",
              "      <td>Burlington, IA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.716044e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.713452e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>FULL_TIME</td>\n",
              "      <td>USD</td>\n",
              "      <td>BASE_SALARY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71c069c5-43af-43bc-98f1-ba3128d524c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71c069c5-43af-43bc-98f1-ba3128d524c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71c069c5-43af-43bc-98f1-ba3128d524c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5bd37b24-e646-4fc5-8d74-4fa843408224\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bd37b24-e646-4fc5-8d74-4fa843408224')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5bd37b24-e646-4fc5-8d74-4fa843408224 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     job_id            company_name  \\\n",
              "0    921716   Corcoran Sawyer Smith   \n",
              "1   1829192                     NaN   \n",
              "2  10998357  The National Exemplar    \n",
              "3  23221523  Abrams Fensterman, LLP   \n",
              "4  35982263                     NaN   \n",
              "\n",
              "                                               title  \\\n",
              "0                              Marketing Coordinator   \n",
              "1                  Mental Health Therapist/Counselor   \n",
              "2                        Assitant Restaurant Manager   \n",
              "3  Senior Elder Law / Trusts and Estates Associat...   \n",
              "4                                 Service Technician   \n",
              "\n",
              "                                         description  max_salary pay_period  \\\n",
              "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
              "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
              "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
              "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
              "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
              "\n",
              "            location  company_id  views  med_salary  ...        expiry  \\\n",
              "0      Princeton, NJ   2774458.0   20.0         NaN  ...  1.715990e+12   \n",
              "1   Fort Collins, CO         NaN    1.0         NaN  ...  1.715450e+12   \n",
              "2     Cincinnati, OH  64896719.0    8.0         NaN  ...  1.715870e+12   \n",
              "3  New Hyde Park, NY    766262.0   16.0         NaN  ...  1.715488e+12   \n",
              "4     Burlington, IA         NaN    3.0         NaN  ...  1.716044e+12   \n",
              "\n",
              "  closed_time  formatted_experience_level  \\\n",
              "0         NaN                         NaN   \n",
              "1         NaN                         NaN   \n",
              "2         NaN                         NaN   \n",
              "3         NaN                         NaN   \n",
              "4         NaN                         NaN   \n",
              "\n",
              "                                         skills_desc   listed_time  \\\n",
              "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
              "1                                                NaN  1.712858e+12   \n",
              "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
              "3  This position requires a baseline understandin...  1.712896e+12   \n",
              "4                                                NaN  1.713452e+12   \n",
              "\n",
              "  posting_domain sponsored  work_type  currency  compensation_type  \n",
              "0            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
              "1            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
              "2            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
              "3            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
              "4            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxjKNoSowJ_h",
        "outputId": "8dda54db-b973-47d2-e5ae-c4ace5de400c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "123849"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKSlx4z9teks",
        "outputId": "c705c863-587c-4924-d112-5a22a30cf54e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121410, 0, 7)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for null values in the columns\n",
        "df['skills_desc'].isnull().sum(), df['title'].isna().sum(), df['description'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AZ_QdRmEnQa",
        "outputId": "64b70e1c-bf8c-4591-b014-a0e586ef27f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-a90e85815c54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['title'] = df_test['title'].str.lower().str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-5-a90e85815c54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['description'] = df_test['description'].str.lower().str.replace('[^\\w\\s]', '')\n"
          ]
        }
      ],
      "source": [
        "# Select the first 20,000 rows, due to compute limit.\n",
        "df_test = df.iloc[:20000]\n",
        "\n",
        "# Preprocess 'title' and 'description' columns:\n",
        "# Convert to lowercase and remove non-alphanumeric characters\n",
        "df_test['title'] = df_test['title'].str.lower().str.replace('[^\\w\\s]', '')\n",
        "df_test['description'] = df_test['description'].str.lower().str.replace('[^\\w\\s]', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYE26zdjBDES",
        "outputId": "1f96f9f2-deb7-4498-b6e8-4989c61763f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_auto_reduce_topics',\n",
              " '_c_tf_idf',\n",
              " '_cluster_embeddings',\n",
              " '_combine_zeroshot_topics',\n",
              " '_create_topic_vectors',\n",
              " '_extract_embeddings',\n",
              " '_extract_representative_docs',\n",
              " '_extract_topics',\n",
              " '_extract_words_per_topic',\n",
              " '_get_param_names',\n",
              " '_guided_topic_modeling',\n",
              " '_images_to_text',\n",
              " '_is_zeroshot',\n",
              " '_map_predictions',\n",
              " '_map_probabilities',\n",
              " '_merged_topics',\n",
              " '_outliers',\n",
              " '_preprocess_text',\n",
              " '_reduce_dimensionality',\n",
              " '_reduce_to_n_topics',\n",
              " '_reduce_topics',\n",
              " '_save_representative_docs',\n",
              " '_sort_mappings_by_frequency',\n",
              " '_top_n_idx_sparse',\n",
              " '_top_n_values_sparse',\n",
              " '_update_topic_size',\n",
              " '_zeroshot_topic_modeling',\n",
              " 'approximate_distribution',\n",
              " 'c_tf_idf_',\n",
              " 'calculate_probabilities',\n",
              " 'ctfidf_model',\n",
              " 'custom_labels_',\n",
              " 'embedding_model',\n",
              " 'find_topics',\n",
              " 'fit',\n",
              " 'fit_transform',\n",
              " 'generate_topic_labels',\n",
              " 'get_document_info',\n",
              " 'get_params',\n",
              " 'get_representative_docs',\n",
              " 'get_topic',\n",
              " 'get_topic_freq',\n",
              " 'get_topic_info',\n",
              " 'get_topic_tree',\n",
              " 'get_topics',\n",
              " 'hdbscan_model',\n",
              " 'hierarchical_topics',\n",
              " 'language',\n",
              " 'load',\n",
              " 'low_memory',\n",
              " 'merge_models',\n",
              " 'merge_topics',\n",
              " 'min_topic_size',\n",
              " 'n_gram_range',\n",
              " 'nr_topics',\n",
              " 'partial_fit',\n",
              " 'probabilities_',\n",
              " 'push_to_hf_hub',\n",
              " 'reduce_outliers',\n",
              " 'reduce_topics',\n",
              " 'representation_model',\n",
              " 'representative_docs_',\n",
              " 'representative_images_',\n",
              " 'save',\n",
              " 'seed_topic_list',\n",
              " 'set_topic_labels',\n",
              " 'top_n_words',\n",
              " 'topic_aspects_',\n",
              " 'topic_embeddings_',\n",
              " 'topic_labels_',\n",
              " 'topic_mapper_',\n",
              " 'topic_representations_',\n",
              " 'topic_sizes_',\n",
              " 'topics_',\n",
              " 'topics_over_time',\n",
              " 'topics_per_class',\n",
              " 'transform',\n",
              " 'umap_model',\n",
              " 'update_topics',\n",
              " 'vectorizer_model',\n",
              " 'verbose',\n",
              " 'visualize_approximate_distribution',\n",
              " 'visualize_barchart',\n",
              " 'visualize_distribution',\n",
              " 'visualize_document_datamap',\n",
              " 'visualize_documents',\n",
              " 'visualize_heatmap',\n",
              " 'visualize_hierarchical_documents',\n",
              " 'visualize_hierarchy',\n",
              " 'visualize_term_rank',\n",
              " 'visualize_topics',\n",
              " 'visualize_topics_over_time',\n",
              " 'visualize_topics_per_class',\n",
              " 'zeroshot_min_similarity',\n",
              " 'zeroshot_topic_list']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Add stopwords to improve model performance\n",
        "stopwords = list(stopwords.words('english')) #+ freq['Representation'][0]\n",
        "\n",
        "# Initialize CountVectorizer with bigrams and stopwords\n",
        "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords)\n",
        "\n",
        "\n",
        "# Initialize BERTopic model with customized CountVectorizer\n",
        "model = BERTopic(\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    language='english', calculate_probabilities=True,\n",
        "\n",
        ")\n",
        "\n",
        "# Check available methods in the BERTopic model\n",
        "dir(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COR7M1tuBZaF",
        "outputId": "205d9b80-b041-4860-d145-905bcb199979"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Topic  Count                                               Name  \\\n",
            "0     -1   5632                     -1_work_experience_team_skills   \n",
            "1      0    418             0_clinical_research_scientific_medical   \n",
            "2      1    214                  1_data_analyst_analytics_business   \n",
            "3      2    208  2_accounting_accountant_financial_senior accou...   \n",
            "4      3    199                      3_galt_earnings_owners_credit   \n",
            "5      4    196  4_administrative_office_administrative assista...   \n",
            "6      5    153              5_security_cybersecurity_cyber_threat   \n",
            "7      6    150  6_account_account manager_sales_account executive   \n",
            "8      7    143  7_practical nurse_licensed practical_nursing_p...   \n",
            "9      8    138                 8_hardware_support_desktop_windows   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [work, experience, team, skills, required, pos...   \n",
            "1  [clinical, research, scientific, medical, regu...   \n",
            "2  [data, analyst, analytics, business, business ...   \n",
            "3  [accounting, accountant, financial, senior acc...   \n",
            "4  [galt, earnings, owners, credit, business owne...   \n",
            "5  [administrative, office, administrative assist...   \n",
            "6  [security, cybersecurity, cyber, threat, infor...   \n",
            "7  [account, account manager, sales, account exec...   \n",
            "8  [practical nurse, licensed practical, nursing,...   \n",
            "9  [hardware, support, desktop, windows, troubles...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [manager, product marketing job title: manager...  \n",
            "1  [msl field director, immunology - rheumatology...  \n",
            "2  [data analyst-tx job title: entry level busine...  \n",
            "3  [accounting manager why work for us?as a famil...  \n",
            "4  [sales manager position summary: our sales man...  \n",
            "5  [administrative assistant- somerset, nj req #:...  \n",
            "6  [sr. cyber security analyst - threat hunter we...  \n",
            "7  [account manager - light industrial title: acc...  \n",
            "8  [licensed practical nurse - the pavilion healt...  \n",
            "9  [pc technician - t2-98 description \\n\\nunder g...  \n"
          ]
        }
      ],
      "source": [
        "# Fit and transform the model on combined 'title' and 'description' data\n",
        "topics, probs = model.fit_transform(df_test['title']+' '+df_test['description'])\n",
        "\n",
        "# Get topic information\n",
        "freq = model.get_topic_info()\n",
        "\n",
        "# Print top 10 topics\n",
        "print(freq.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Cf7BX-diBn_0"
      },
      "outputs": [],
      "source": [
        "# Define search terms related to data science and ML and filter topics that contain the search terms to identify the AI/ML clusters.\n",
        "search_terms = ['data', 'science', 'machine', 'learning', 'artificial', 'intelligence']\n",
        "idx = []\n",
        "for ind, row in freq.iterrows():\n",
        "  for i in search_terms:\n",
        "      if i in row['Name'] or i in row['Representation']:\n",
        "          idx.append(ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "682K7ttqBn8u"
      },
      "outputs": [],
      "source": [
        "# Example job description for testing\n",
        "example = [\"\"\"Machine Learning Model Engineer Samsung Ads is an advanced advertising technology company in rapid growth that focuses on enabling brands to connect with Samsung TV audiences as they are exposed to digital media by using the industry’s most comprehensive data to build the world’s smartest advertising platform. Being part of an international company such as Samsung and doing business around the world means that we get to work on the most challenging projects with stakeholders and teams located around the globe.\n",
        "We are proud to have built a world-class organization grounded in an entrepreneurial and collaborative spirit. Working at Samsung Ads offers one of the best environments in the industry to learn just how fast you can grow, how much you can achieve, and how good you can be. We thrive on problem-solving, breaking new ground, and enjoying every part of the journey. Machine learning lies in the core of the advertising industry. This is no exception to Samsung Ads. At Samsung Ads, we are actively exploring the latest machine learning techniques to improve our existing systems and products and create new revenue streams. As a machine learning model engineer of the Samsung Ads Platform Intelligence (PI) team, you will have access to unique Samsung proprietary data to develop and deploy a wide spectrum of large-scale machine learning products with real-world impact. You will work closely with and be supported by a talented engineering team and top-notch researchers to work on exciting machine learning projects and state-of-the-art technologies. You will be welcomed by a unique learning culture and creative work atmosphere. This is an exciting and unique opportunity to get deeply involved in envisioning, designing and implementing cutting-edge machine learning products with a growing team.\"\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh_vvryXBn1H",
        "outputId": "9093560b-8a74-4c0b-a053-a06ec15fb895"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[48]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform the example job description using the trained model\n",
        "res = model.transform(example)\n",
        "res[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMeW6s_5CQnk",
        "outputId": "a54b7824-5a70-4c50-93a4-af20cfed0f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Predicted label for example is  48 48_ai_machine learning_machine_ml\n"
          ]
        }
      ],
      "source": [
        "# Print the predicted topic label and its description\n",
        "print(\"The Predicted label for example is \", res[0][0], model.topic_labels_[res[0][0]])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rI9Jgpz2sNB1",
        "nzWNefz7tHm2",
        "I3Y3kWRJwXD1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
